"use strict";(self.webpackChunkllm_tse_scratch=self.webpackChunkllm_tse_scratch||[]).push([[195],{5639:(e,t,a)=>{a.r(t),a.d(t,{default:()=>j});var r=a(7294),l=a(9960),n=a(2263),o=a(7961);const i={features:"features_QA7r",featureSvg:"featureSvg_Ggsy",abstract:"abstract_CGn4",table:"table_q78j"};var s=a(859),u=a(9965),v=a(6074),c=a(264),m=a(5968),w=a(6226);const d=a.p+"assets/images/scenarios-341b28b5280b4e1ccfde68d4b21163d1.png",p=a.p+"assets/images/diff-bc1be2126ce81a50e6d9109bbe024b43.png",h=a.p+"assets/images/model_arch-ad318957502d3ddd728e8bf3b5dd4a3c.png";var x=a(7062);const{Meta:g}=s.default,{Title:_,Paragraph:E,Text:f}=u.default,y=[{title:"Mixture",dataIndex:"mixture",key:"mixture",render:e=>r.createElement("audio",{controls:!0,src:e},r.createElement("source",{type:"audio/wav"})),width:200},{title:"Enrollment (Audio)",dataIndex:"enrollAudio",key:"enrollAudio",render:e=>e?r.createElement("audio",{controls:!0,src:e},r.createElement("source",{type:"audio/wav"})):r.createElement(f,{type:"danger"},"w/o"),width:200},{title:"Enrollment (Text)",dataIndex:"enrollText",key:"enrollText",render:e=>e?r.createElement(f,null,e):r.createElement(f,{type:"danger"},"w/o"),width:200},{title:"Separated",dataIndex:"separated",key:"separated",render:e=>r.createElement("audio",{controls:!0,src:e},r.createElement("source",{type:"audio/wav"})),width:200}],T=[{key:"30",mixture:"wav/00030_mixture.wav",enrollText:"Extract the speaker who is saying 'the mixture the affected parts' from this audio?",separated:"wav/00030_attr.wav",groundTruth:"wav/00030_target.wav"},{key:"30",mixture:"wav/00030_mixture.wav",enrollAudio:"wav/00030_enroll.wav",separated:"wav/00030_voiceprint.wav",groundTruth:"wav/00030_target.wav"},{key:"30",mixture:"wav/00030_mixture.wav",enrollAudio:"wav/00030_enroll.wav",enrollText:"Please note that the person speaking 'the mixture the affected parts' in the mixed audio should be extracted.",separated:"wav/00030_live.wav",groundTruth:"wav/00030_target.wav"},{key:"30",mixture:"wav/00030_mixture.wav",enrollAudio:"wav/00030_enroll.wav",enrollText:r.createElement(r.Fragment,null,"I ",r.createElement(f,{mark:!0},"don't want to")," the given voice of in this audio."),separated:"wav/00030_control.wav"},{key:"73",mixture:"wav/00073_mixture.wav",enrollText:"I need 'it was plain that only the ponies could go by it' spotted from this audio.",separated:"wav/00073_attr.wav",groundTruth:"wav/00073_target.wav"},{key:"73",mixture:"wav/00073_mixture.wav",enrollAudio:"wav/00073_enroll.wav",separated:"wav/00073_voiceprint.wav",groundTruth:"wav/00073_target.wav"},{key:"73",mixture:"wav/00073_mixture.wav",enrollAudio:"wav/00073_enroll.wav",enrollText:"Please extract 'it was plain that only the ponies could go by it' in the mixed audio.",separated:"wav/00073_live.wav",groundTruth:"wav/00073_target.wav"},{key:"73",mixture:"wav/00073_mixture.wav",enrollAudio:"wav/00073_enroll.wav",enrollText:r.createElement(r.Fragment,null,"Is it possible to ",r.createElement(f,{mark:!0},"erase")," the given voice from this audio?"),separated:"wav/00073_control.wav"}],k=[{key:"42",mixture:"wav/00042_mixture.wav",enrollText:"Could you support me in identifying and extracting the voice of male from this audio?",separated:"wav/00042_attr.wav",groundTruth:"wav/00042_target.wav"},{key:"42",mixture:"wav/00042_mixture.wav",enrollAudio:"wav/00042_enroll.wav",separated:"wav/00042_voiceprint.wav",groundTruth:"wav/00042_target.wav"},{key:"42",mixture:"wav/00042_mixture.wav",enrollAudio:"wav/00042_enroll.wav",enrollText:"The male voice in the mixed audio should be extracted.",separated:"wav/00042_live.wav",groundTruth:"wav/00042_target.wav"},{key:"42",mixture:"wav/00042_mixture.wav",enrollAudio:"wav/00042_enroll.wav",enrollText:r.createElement(r.Fragment,null,"Can you ",r.createElement(f,{mark:!0},"remove")," the specified voice from this audio?"),separated:"wav/00042_control.wav"},{key:"87",mixture:"wav/00087_mixture.wav",enrollText:"Can you extract the specific voice of male from this audio?",separated:"wav/00087_attr.wav",groundTruth:"wav/00087_target.wav"},{key:"87",mixture:"wav/00087_mixture.wav",enrollAudio:"wav/00087_enroll.wav",separated:"wav/00087_voiceprint.wav",groundTruth:"wav/00087_target.wav"},{key:"87",mixture:"wav/00087_mixture.wav",enrollAudio:"wav/00087_enroll.wav",enrollText:"The extracted speaker should be a man.",separated:"wav/00087_live.wav",groundTruth:"wav/00087_target.wav"},{key:"87",mixture:"wav/00087_mixture.wav",enrollAudio:"wav/00087_enroll.wav",enrollText:r.createElement(r.Fragment,null,"Please ",r.createElement(f,{mark:!0},"remove")," the specified voice from this audio."),separated:"wav/00087_control.wav"}],b=[{key:"47",mixture:"wav/00047_mixture.wav",enrollText:"Is it possible to isolate the Spanish voice in this speech mix?",separated:"wav/00047_attr.wav",groundTruth:"wav/00047_target.wav"},{key:"47",mixture:"wav/00047_mixture.wav",enrollAudio:"wav/00047_enroll.wav",separated:"wav/00047_voiceprint.wav",groundTruth:"wav/00047_target.wav"},{key:"47",mixture:"wav/00047_mixture.wav",enrollAudio:"wav/00047_enroll.wav",enrollText:"Please extract the Spanish voice in the mixed audio.",separated:"wav/00047_live.wav",groundTruth:"wav/00047_target.wav"},{key:"47",mixture:"wav/00047_mixture.wav",enrollAudio:"wav/00047_enroll.wav",enrollText:r.createElement(r.Fragment,null,r.createElement(f,{mark:!0},"Eliminate")," the given voice from this audio."),separated:"wav/00047_control.wav"},{key:"90",mixture:"wav/00090_mixture.wav",enrollText:"Would you be able to assist me in isolating the English voice from this mixture speech?",separated:"wav/00090_attr.wav",groundTruth:"wav/00090_target.wav"},{key:"90",mixture:"wav/00090_mixture.wav",enrollAudio:"wav/00090_enroll.wav",separated:"wav/00090_voiceprint.wav",groundTruth:"wav/00090_target.wav"},{key:"90",mixture:"wav/00090_mixture.wav",enrollAudio:"wav/00090_enroll.wav",enrollText:"Please extract the English voice in the mixed audio.",separated:"wav/00090_live.wav",groundTruth:"wav/00090_target.wav"},{key:"90",mixture:"wav/00090_mixture.wav",enrollAudio:"wav/00090_enroll.wav",enrollText:r.createElement(r.Fragment,null,"Please ",r.createElement(f,{mark:!0},"remove")," the specified voice from this audio."),separated:"wav/00090_control.wav"}],Z=[{key:"160",mixture:"wav/00160_mixture.wav",enrollText:"Help me extract the speech signal of the loudest speaker.",separated:"wav/00160_attr.wav",groundTruth:"wav/00160_target.wav"},{key:"160",mixture:"wav/00160_mixture.wav",enrollAudio:"wav/00160_enroll.wav",separated:"wav/00160_voiceprint.wav",groundTruth:"wav/00160_target.wav"},{key:"160",mixture:"wav/00160_mixture.wav",enrollAudio:"wav/00160_enroll.wav",enrollText:"Notice that the loudest sound in the mixed audio should be extracted.",separated:"wav/00160_live.wav",groundTruth:"wav/00160_target.wav"},{key:"160",mixture:"wav/00160_mixture.wav",enrollAudio:"wav/00160_enroll.wav",enrollText:r.createElement(r.Fragment,null,r.createElement(f,{mark:!0},"Remove")," the given voice from the mixtrue."),separated:"wav/00160_control.wav"},{key:"240",mixture:"wav/00240_mixture.wav",enrollText:"Help me retrieve the speech signal corresponding to far away from the microphone.",separated:"wav/00240_attr.wav",groundTruth:"wav/00240_target.wav"},{key:"240",mixture:"wav/00240_mixture.wav",enrollAudio:"wav/00240_enroll.wav",separated:"wav/00240_voiceprint.wav",groundTruth:"wav/00240_target.wav"},{key:"240",mixture:"wav/00240_mixture.wav",enrollAudio:"wav/00240_enroll.wav",enrollText:"The speaker is far away from the microphone, and the reverberat is very serious.",separated:"wav/00240_live.wav",groundTruth:"wav/00240_target.wav"},{key:"240",mixture:"wav/00240_mixture.wav",enrollAudio:"wav/00240_enroll.wav",enrollText:r.createElement(r.Fragment,null,r.createElement(f,{mark:!0},"Eliminate")," the registered voice from this audio."),separated:"wav/00240_control.wav"}];function A(){return r.createElement(r.Fragment,null,r.createElement(m.Z,{justify:"center"},r.createElement(_,{level:2},"Abstract")),r.createElement(m.Z,{justify:"center"},r.createElement(w.Z,{span:12},r.createElement(u.default,null,r.createElement(E,null,"Humans possess an extraordinary ability to selectively focus on the sound source of interest amidst complex acoustic environments, commonly referred to as cocktail party scenarios. In an attempt to replicate this remarkable auditory attention capability in machines, target speaker extraction (TSE) models have been developed. These models leverage the pre-registered cues of the target speaker to extract the sound source of interest. However, the effectiveness of these models is hindered in real-world scenarios due to the unreliable or even absence of pre-registered cues. To address this limitation, this study investigates the integration of natural language description to enhance the feasibility, controllability, and performance of existing TSE models. Specifically, we propose a model named LLM-TSE, wherein a large language model (LLM) extracts useful semantic cues from the user's typed text input. These cues can serve as independent extraction cues, task selectors to control the TSE process or complement the pre-registered cues. Our experimental results demonstrate competitive performance when only text-based cues are presented, the effectiveness of using input text as a task selector, and a new state-of-the-art when combining text-based cues with pre-registered cues. To our knowledge, this is the first study to successfully incorporate LLMs to guide target speaker extraction, which can be a cornerstone for cocktail party problem research.")))),r.createElement(v.Z,null),r.createElement(m.Z,{justify:"center"},r.createElement(w.Z,{span:10},r.createElement(s.default,{cover:r.createElement(x.Z,{src:p})},r.createElement(g,{description:"Comparison between the conventional TSE system and our proposed LLM-TSE system. The conventional systems rely on the pre-registered voiceprint of the target speaker as an extraction cue, while our system offers the flexibility to incorporate text-based cues to facilitate the target speaker extraction process."})))),r.createElement(m.Z,{justify:"center"},r.createElement(w.Z,{span:10},r.createElement(s.default,{cover:r.createElement(x.Z,{src:d})},r.createElement(g,{description:"New application scenarios enabled by the proposed LLM-TSE."})))),r.createElement(m.Z,{justify:"center"},r.createElement(w.Z,{span:10},r.createElement(s.default,{cover:r.createElement(x.Z,{src:h})},r.createElement(g,{description:"Overview of the proposed LLM-TSE model architecture."})))),r.createElement(v.Z,null),r.createElement(v.Z,null),r.createElement(m.Z,{justify:"center"},r.createElement(_,{level:2},"Demo")),r.createElement(v.Z,null,"Transcription Snippets"),r.createElement(c.Z,{className:i.table,dataSource:T,columns:y,size:"middle",pagination:!1}),r.createElement(v.Z,null,"Loudness or Far/Near"),r.createElement(c.Z,{className:i.table,dataSource:Z,columns:y,size:"middle",pagination:!1}),r.createElement(v.Z,null,"Gender"),r.createElement(c.Z,{className:i.table,dataSource:k,columns:y,size:"middle",pagination:!1}),r.createElement(v.Z,null,"Language"),r.createElement(c.Z,{className:i.table,dataSource:b,columns:y,size:"middle",pagination:!1}))}var S=a(8610);const L={banner:"banner_d9gt",title:"title_GqtP",links:"links_ykh6"};var N=a(9354),P=a(1210);const{Title:C,Text:F}=u.default;function I(){const{siteConfig:e}=(0,n.Z)();return r.createElement(u.default,{className:L.banner},r.createElement(C,{level:2,className:L.title},e.title),r.createElement(C,{level:3,className:L.title},"Xiang Hao",r.createElement("sup",null,"1,2"),", Jibin Wu",r.createElement("sup",null,"1,*"),", Jianwei Yu",r.createElement("sup",null,"2"),", Chenglin Xu",r.createElement("sup",null,"1"),", and Kay Chen Tan",r.createElement("sup",null,"1")),r.createElement(C,{level:5,className:L.title},r.createElement("sup",null,"1"),"The Hong Kong Polytechnic University, ",r.createElement("sup",null,"2"),"Tencent AI Lab"),r.createElement(v.Z,null),r.createElement(m.Z,{justify:"center",align:"middle",className:L.links},r.createElement(S.ZP,{type:"default",icon:r.createElement(N.Z,null)},r.createElement(l.Z,{to:"https://arxiv.org/abs/2310.07284"},"Paper")),r.createElement(v.Z,{type:"vertical"}),r.createElement(S.ZP,{type:"default",icon:r.createElement(P.Z,null)},r.createElement(l.Z,{to:"https://github.com/haoxiangsnr/llm-tse/"},"Github"))))}function j(){const{siteConfig:e}=(0,n.Z)();return r.createElement(o.Z,{title:`${e.projectName}`,description:"Description will go into a meta tag in <head />"},r.createElement(I,null),r.createElement(v.Z,null),r.createElement(A,null))}}}]);